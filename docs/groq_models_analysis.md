# Groq Model Analiz ve Entegrasyon Raporu

**Tarih:** 23 AralÄ±k 2025  
**Konu:** Llama 4, Qwen 3, Kimi k2 ve DiÄŸer Groq Modellerinin Ä°ncelemesi  
**Durum:** `Preview` ve `Production` Modelleri

Bu rapor, Groq platformunda listelenen belirli AI modellerinin teknik Ã¶zelliklerini, kullanÄ±m amaÃ§larÄ±nÄ± ve **Mami AI** projesine entegrasyon potansiyellerini detaylandÄ±rmaktadÄ±r.

---

## ðŸ“‹ YÃ¶netici Ã–zeti

Ä°ncelenen liste, Ã¶zellikle **Llama 4 (Preview)**, **Qwen 3** ve **Kimi k2** gibi Ã§ok yeni ve gÃ¼Ã§lÃ¼ modelleri iÃ§ermektedir. Bu modeller, mevcut `1upgrade_plan.md` iÃ§erisindeki hedeflerle (Ã¶zellikle Reasoning, Coding ve Multimodal kapasite) doÄŸrudan Ã¶rtÃ¼ÅŸmektedir.

| Model Ailesi | Ã–ne Ã‡Ä±kan Ã–zellik | Projedeki OlasÄ± RolÃ¼ | Durum |
| :--- | :--- | :--- | :--- |
| **Llama 4 (Maverick/Scout)** | Multimodal (Resim+Metin), MoE Mimarisi | Vision analizi, Genel sohbet | ðŸš§ Preview |
| **Qwen 3** | ÃœstÃ¼n MantÄ±k (Reasoning) ve Matematik | Kodlama, KarmaÅŸÄ±k mantÄ±k sorularÄ± | ðŸš§ Preview |
| **Kimi k2** | 1 Trilyon Parametre + 256K Context | Uzun belge analizi (RAG Deep), Ajan (Agent) iÅŸleri | ðŸš§ Preview |
| **Llama Guard 4** | Multimodal GÃ¼venlik | GÃ¶rsel ve metin moderasyonu (SansÃ¼r/GÃ¼venlik) | âœ… Production |
| **Whisper V3 Turbo** | AÅŸÄ±rÄ± HÄ±zlÄ± STT (216x) | GerÃ§ek zamanlÄ± sesli asistan (Faz 6) | âœ… Production |

---

## 1. Model Analizleri

### ðŸ¤– Generative & Reasoning Modelleri

#### 1.1. Moonshot AI - Kimi k2 (Instruct & 0905)
*   **Model:** `moonshotai/kimi-k2-instruct-0905`
*   **Boyut:** ~1 Trilyon Parametre (MoE - Mixture of Experts)
*   **Context Window:** **256,000 Token** (Ã‡ok GeniÅŸ)
*   **KullanÄ±m AmacÄ±:** Uzun baÄŸlam gerektiren analizler, kodlama, karmaÅŸÄ±k ajan gÃ¶revleri.
*   **GÃ¼Ã§lÃ¼ YÃ¶nleri:** 
    *   Scoding (Kodlama) baÅŸarÄ±sÄ± (LiveCodeBench: %53.7).
    *   Ã‡ok uzun belgeleri (kitap, tÃ¼m kod tabanÄ±) hafÄ±zada tutabilme.
    *   MoE yapÄ±sÄ± sayesinde devasa boyutuna raÄŸmen hÄ±zlÄ± Ã§Ä±karÄ±m.
*   **Proje KullanÄ±mÄ±:** 
    *   **Uzun Belge RAG:** `docs/1upgrade_plan.md` iÃ§inde belirtilen "Page-aware PDF ingestion" sonrasÄ±, kitabÄ±n tamamÄ±nÄ± context'e atÄ±p soru sormak iÃ§in ideal.
    *   **Kod AsistanÄ±:** Projede kod yazma gÃ¶revleri iÃ§in DeepSeek alternatifi olabilir.

#### 1.2. Qwen 3 (32B)
*   **Model:** `qwen/qwen3-32b`
*   **Boyut:** 32 Milyar Parametre
*   **Context Window:** 128,000 Token
*   **KullanÄ±m AmacÄ±:** Matematik, MantÄ±k YÃ¼rÃ¼tme (Reasoning), ve Bilimsel problemler.
*   **GÃ¼Ã§lÃ¼ YÃ¶nleri:**
    *   **Reasoning:** "Thinking Mode" desteÄŸi ile adÄ±m adÄ±m dÃ¼ÅŸÃ¼nerek cevap verir.
    *   **Performans:** ArenaHard testinde %93.8 gibi olaÄŸanÃ¼stÃ¼ bir skor (GPT-4 seviyesi rakiplerle yarÄ±ÅŸÄ±r).
*   **Proje KullanÄ±mÄ±:**
    *   **Logic Router:** `smart_router.py` gÃ¼ncellenerek matematik, fizik veya mantÄ±k sorularÄ± (`domain="math"`) bu modele yÃ¶nlendirilmeli.
    *   **Mevcut Plan:** Upgrade planÄ±ndaki "Reasoning (qwen-32b)" maddesi iÃ§in en gÃ¼ncel ve doÄŸru aday budur.

#### 1.3. Llama 4 (Maverick & Scout) - **PREVIEW**
Meta'nÄ±n henÃ¼z tam lansmanÄ±nÄ± yapmadÄ±ÄŸÄ± (veya Groq'a Ã¶zel/erken eriÅŸim) yeni nesil model ailesi.
*   **Varyasyonlar:**
    *   `meta-llama/llama-4-maverick-17b-128e-instruct`: 17B parametre, **128 Expert** (MoE). Daha yÃ¼ksek kapasite.
    *   `meta-llama/llama-4-scout-17b-16e-instruct`: 17B parametre, **16 Expert** (MoE). Daha hafif/hÄ±zlÄ±.
*   **Boyut:** 17 Milyar (Base), ancak MoE yapÄ±sÄ± ile efektif kapasite Ã§ok daha yÃ¼ksek.
*   **Ã–zellik:** **Natively Multimodal** (Metin + Resim girdisi kabul eder).
*   **Performans:** DocVQA (Belge Ã¼zerinden soru cevaplama) skoru **94.4** ile Ã§ok yÃ¼ksek.
*   **Proje KullanÄ±mÄ±:**
    *   **Vision/GÃ¶rsel Analiz:** Projede ÅŸu an eksik olan "Resim yÃ¼kleyip soru sorma" Ã¶zelliÄŸi iÃ§in kullanÄ±lmalÄ±. Llama 3.2 Vision yerine bu modeller (daha yeni mimari) denenebilir.
    *   **Genel Sohbet:** HÄ±zlÄ± ve zeki bir orta-boyut model olarak Llama 3.3 70B'ye alternatif (daha dÃ¼ÅŸÃ¼k maliyet/hÄ±z dense) olabilir.

#### 1.4. OpenAI GPT-OSS (Groq Entegrasyonu)
*   **Model:** `openai/gpt-oss-safeguard-20b` (ve 120B versiyonu)
*   **Boyut:** 20B (Safeguard versiyonu)
*   **AmaÃ§:** OpenAI'Ä±n aÃ§Ä±k aÄŸÄ±rlÄ±klÄ± (open-weights) modelleri Ã¼zerine kurulu gÃ¼venlik ve politika takip modeli.
*   **Ã–zellik:** "Harmony format" ile yapÄ±landÄ±rÄ±lmÄ±ÅŸ gÃ¼venlik gerekÃ§eleri sunar.

---

### ðŸ›¡ï¸ GÃ¼venlik ve Moderasyon Modelleri

Bu modeller son kullanÄ±cÄ±ya cevap vermek iÃ§in deÄŸil, giren/Ã§Ä±kan mesajÄ± denetlemek iÃ§indir.

*   **`meta-llama/llama-guard-4-12b`**:
    *   **Ã–nemi:** En gÃ¼ncel Llama gÃ¼venlik modeli.
    *   **Yetenek:** Hem metin hem **gÃ¶rsel** (Image inputs) gÃ¼venliÄŸini denetleyebilir.
    *   **Proje:** `router` katmanÄ±nda "NSFW Image" kontrolÃ¼ iÃ§in regex yerine bu model kullanÄ±labilir. Daha akÄ±llÄ± ve "context-aware" sansÃ¼r saÄŸlar.

*   **`meta-llama/llama-prompt-guard-2` (86m & 22m)**:
    *   **Boyut:** Ã‡ok kÃ¼Ã§Ã¼k (86 Milyon / 22 Milyon).
    *   **AmaÃ§:** **Prompt Injection** ve **Jailbreak** saldÄ±rÄ±larÄ±nÄ± tespit etmek.
    *   **HÄ±z:** Ã‡ok kÃ¼Ã§Ã¼k olduÄŸu iÃ§in milisaniyeler sÃ¼rer, ana akÄ±ÅŸÄ± yavaÅŸlatmaz.
    *   **Proje:** KullanÄ±cÄ± girdisi LLM'e gitmeden Ã¶nce bu modelden geÃ§irilmeli (`Stage 1: Intent & Guard` aÅŸamasÄ±).

---

### ðŸŽ™ï¸ Ses Modelleri

*   **`whisper-large-v3-turbo`**:
    *   **AmaÃ§:** Speech-to-Text (KonuÅŸmayÄ± yazÄ±ya dÃ¶kme).
    *   **FarkÄ±:** Standart V3'ten Ã§ok daha hÄ±zlÄ± (216x speed factor).
    *   **Proje:** Faz 6'da planlanan "Voice Input" Ã¶zelliÄŸi iÃ§in **kesinlikle** bu model kullanÄ±lmalÄ±. KullanÄ±cÄ± konuÅŸurken bekleme sÃ¼resini (latency) minimize eder.

*   **`playai-tts`**:
    *   **AmaÃ§:** Text-to-Speech (YazÄ±yÄ± sese Ã§evirme).
    *   **Not:** Groq dÃ¶kÃ¼manlarÄ±nda doÄŸrudan yer almasa da (genellikle partner modeldir), yÃ¼ksek kaliteli ve duygusal tonlamalÄ± ses Ã¼retimi iÃ§in kullanÄ±lÄ±r. ElevenLabs alternatifidir.

---

## 2. KarÅŸÄ±laÅŸtÄ±rma ve Ã–neriler

### Kodlama ve MantÄ±k Ä°Ã§in:
*   **Kazanan:** `qwen/qwen3-32b`
*   **Alternatif:** `moonshotai/kimi-k2-instruct-0905` (EÄŸer Ã§ok uzun dosya okunacaksa)
*   **Neden:** Qwen 3'Ã¼n matematik ve mantÄ±k skorlarÄ± (ArenaHard %93.8) rakiplerinden Ã§ok Ã¶nde.

### Genel Sohbet ve HÄ±z Ä°Ã§in:
*   **Kazanan:** `meta-llama/llama-3.3-70b-versatile` (Halen en dengeli production modeli)
*   **Denenmeli:** `meta-llama/llama-4-maverick-17b` (Daha dÃ¼ÅŸÃ¼k gecikme ve multimodal yetenek gerekirse).

### GÃ¼venlik Ä°Ã§in:
*   Mevcut Regex yapÄ±sÄ± (`smart_router.py`) hÄ±zlÄ± ama yetersizdir.
*   **Ã–neri:** `llama-prompt-guard-2-86m` modelini router'Ä±n en baÅŸÄ±na ekleyin. Maliyeti ve sÃ¼resi ihmal edilebilir dÃ¼zeydedir ancak gÃ¼venliÄŸi enterprise seviyesine taÅŸÄ±r.

## 3. Proje Entegrasyon PlanÄ± (Ã–zet)

Mevcut `1upgrade_plan.md` gÃ¼ncellenerek ÅŸu modeller plana dahil edilmelidir:

1.  **Router AÅŸamasÄ±:** Regex -> `llama-prompt-guard-2-86m` (Injection KorumasÄ±).
2.  **Logic/Math Ä°stekleri:** -> `qwen/qwen3-32b` (DeepSeek yerine dÃ¼ÅŸÃ¼nÃ¼lebilir).
3.  **Vision (Resimden Soru):** -> `meta-llama/llama-4-maverick-17b` (Yeni Ã¶zellik).
4.  **Sesli Asistan:** -> `whisper-large-v3-turbo` (HÄ±z iÃ§in).

### Ã–rnek `decider.py` GÃ¼ncellemesi (Konsept)

```python
# Matematik sorusu ise Qwen 3 kullan
if domain == "math" or domain == "code":
    model = "qwen/qwen3-32b"
# Resim analizi ise Llama 4 kullan
elif intent == "vision":
    model = "meta-llama/llama-4-maverick-17b-128e-instruct"
# Genel sohbet
else:
    model = "llama-3.3-70b-versatile"
```
